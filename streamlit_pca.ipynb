{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting init.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile init.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from bokeh.plotting import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('data/wine.data', sep = ',',names=range(1, 15, 1))\n",
    "\n",
    "st.title('Principal Component Analysis (PCA)')\n",
    "st.markdown(\"\"\"\n",
    "Esse é um aplicativo simples para analisarmos as componentes principais de um dataset de Classificação de Vinhos. Os dados são resultados de uma análise química de vinhos cultivados na mesma região da Itália, mas derivados de três cultivares diferentes. A análise determinou as quantidades de 13 constituintes encontrados em cada um dos três tipos de vinhos.\n",
    "* **Python libraries:** pandas, numpy, scikit-learn and streamlit \n",
    "* **Data source:** [Dataset-Wine](https://archive.ics.uci.edu/ml/datasets/Wine)\n",
    "\"\"\")\n",
    "\n",
    "st.sidebar.header('Parâmetros do Modelo')\n",
    "\n",
    "def user_input_features():\n",
    "    num_componentes = st.sidebar.slider('Número de Componentes Principais: ',1,13,5)\n",
    "    num_vizinhos = st.sidebar.slider('Número de Vizinhos mais próximos(KNN): ',1,10,5)\n",
    "    return num_componentes, num_vizinhos\n",
    "\n",
    "#num_comp = user_input_features()\n",
    "    \n",
    "st.header('Exibição do Dataset')\n",
    "st.write(\"Dimensão dos dados {} linhas e {} colunas\".format(str(df.shape[0]), str(df.shape[1])))\n",
    "st.dataframe(df)\n",
    "\n",
    "def filedownload(df):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode()).decode()\n",
    "    href = f'<a href=\"data:file/csv;base64,{b64}\" download = \"wine.csv\">Dowload CSV File</a>'\n",
    "    return href\n",
    "\n",
    "st.markdown(filedownload(df), unsafe_allow_html=True)\n",
    "\n",
    "#Mapa de calor\n",
    "if st.button('Mapa de Calor'):\n",
    "    st.header('Mapa de calor de correlação dos dados')\n",
    "    st.write('Por esse mapa de calor a gente consegue visualizar como as variáveis se relacionam entre si e as dependências lineares.')\n",
    "    corr = df.drop(columns=[1]).corr()\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask [np.triu_indices_from(mask)] = True\n",
    "    with sns.axes_style('white'):\n",
    "        f,ax=plt.subplots(figsize=(7,5))\n",
    "        ax = sns.heatmap(corr, mask=mask, vmax=1, square=True)\n",
    "    st.pyplot(f)\n",
    "\n",
    "#Dados Padronizados\n",
    "scaled = df.to_numpy()\n",
    "x = scaled[:, 1:14].copy()\n",
    "y = scaled[:, 0].copy()\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(x)\n",
    "names = []\n",
    "for i in range(1, 14, 1):\n",
    "    names.append('PC {}'.format(i))\n",
    "names.append('Target')\n",
    "df_autovetores=pd.DataFrame(principalComponents)\n",
    "finalDf = pd.concat([df_autovetores, df [[1]]], axis = 1)\n",
    "finalDf.columns = names\n",
    "\n",
    "#Autovalores e autovetore\n",
    "if st.button('Principais Componentes'):\n",
    "    st.header('Dataset em função das suas componentes principais')\n",
    "    st.write('Quando padronizamos os nossos dados, nós fazemos duas operações. Centralizamos o espaço de dados, para evidenciar as relações lineares que existem entre os atributos. E, fazemos o reescalonamento dos dados, para as medidas de escalas não atrapalharem na hora da produção do nosso modelo.')\n",
    "    st.dataframe(finalDf)\n",
    "\n",
    "#Variância explicada\n",
    "if st.button('Variância explicada'):\n",
    "    st.header('Soma acumulada das variâncias')\n",
    "    st.write('Toda componente principal tem um autovalor associado, as componentes de mais importância tem os maiores autovalores. A soma dos autovalores é igual soma acumulada da variância dos nossos dados originais. Desse modo, podemos diminuir a dimensão do nosso dataset sem perder muita informação ao definir de quanto de informação queremos. Quando diminuimos a dimensão do nosso dataset, pode facilitar na análise dos nossos dados e diminuir redudâncias de dados.')\n",
    "    matrizcov = np.corrcoef(x, rowvar=0)\n",
    "    autovalores, _ = np.linalg.eig(matrizcov)\n",
    "    idx = autovalores.argsort()[::-1]   \n",
    "    autovalores = autovalores[idx]\n",
    "    soma_acumulada = []\n",
    "    soma_auto = np.sum(autovalores)\n",
    "    soma = 0\n",
    "    for i in range(0, len(autovalores)):\n",
    "        if len(soma_acumulada) == 0:\n",
    "            soma+=(autovalores[i]/soma_auto)*100\n",
    "            soma_acumulada.append(soma)\n",
    "        else:\n",
    "            soma+=(autovalores[i]/soma_auto)*100\n",
    "            soma_acumulada.append(soma)\n",
    "    df_var_explicada= pd.DataFrame(soma_acumulada, columns=['VariânciaExplicada'])\n",
    "    df_var_explicada.index = range(1,14,1)\n",
    "    p = figure(\n",
    "        title='Soma acumulada das importâncias de cada componente principal:',\n",
    "        x_axis_label='Número de Componentes',\n",
    "        y_axis_label='Variância Explicada(%)')\n",
    "    \n",
    "    \n",
    "    p.scatter(df_var_explicada.index, df_var_explicada['VariânciaExplicada'], line_width=2)\n",
    "    #st.pyplot(fig)\n",
    "    st.bokeh_chart(p, use_container_width=True)\n",
    "\n",
    "X = finalDf.drop(columns=['Target']).copy()\n",
    "Y = finalDf['Target'].copy()\n",
    "#Número de componentes principais que eu vou usar\n",
    "num_pcs, num_vizinho = user_input_features()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X[:][names[:num_pcs]], Y, test_size = 0.30)\n",
    "knn = KNeighborsClassifier(n_neighbors=num_vizinho)\n",
    "#Train the model using the training sets\n",
    "knn.fit(x_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct\n",
    "st.header('Criando um modelo usando PCA')\n",
    "st.write(\"\"\"\n",
    "Para fins didáticos, você pode passar alguns parâmetros para criarmos um modelo de machine learning. Você pode passar o número de componentes principais, a fim de visualizar como o número de dimensões pode afetar a criação do nosso modelo. Além disso, vamos usar o algoritmo K-Nearest Neighbors(KNN) para criarmos o nosso modelo, assim, pode definir o número de vizinhos mais próximos que o algoritmo tem que usar para criar um modelo para as componentes principais e o dataset original. Assim, vamos comparar a precisão de classificar um vinho entre as componentes principais e o dataset original. \n",
    "\"\"\")\n",
    "st.subheader('Performance do dataset usando {} Componentes Principais'.format(num_pcs))\n",
    "st.write(\"Acurácia: \",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#dataset original\n",
    "X2 = df.drop(columns=[1]).copy()\n",
    "Y2 = df[1].copy()\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size = 0.30)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=num_vizinho)\n",
    "#Train the model using the training sets\n",
    "knn2.fit(x_train2, y_train2)\n",
    "#Predict the response for test dataset\n",
    "y_pred2 = knn2.predict(x_test2)\n",
    "st.subheader('Performance do dataset original usando {} vizinhos'.format(num_vizinho))\n",
    "st.write(\"Acurácia: \",metrics.accuracy_score(y_test2, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
